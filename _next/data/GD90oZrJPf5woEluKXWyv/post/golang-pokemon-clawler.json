{"pageProps":{"post":{"title":"Golang Pokemon Clawler","date":1618358400,"slug":"golang-pokemon-clawler","author":"kaichi","content":"<h2>前言</h2>\n<p>最近想弄点数据来练手，遂就想到从网上爬点儿 pokemon 的信息。刚好最近学 go，于是就想用 go 来实现，随便推荐 <a href=\"https://books.studygolang.com/gopl-zh/\">go 语言圣经</a> 这本书。这是我第一个爬 🐛 项目，实现的也很简单。源 <a href=\"https://wiki.52poke.com/wiki/%E5%AE%9D%E5%8F%AF%E6%A2%A6%E5%88%97%E8%A1%A8%EF%BC%88%E6%8C%89%E5%85%A8%E5%9B%BD%E5%9B%BE%E9%89%B4%E7%BC%96%E5%8F%B7%EF%BC%89/%E7%AE%80%E5%8D%95%E7%89%88\">wiki.52poke.com</a>， 解析 html 用到 <a href=\"https://pkg.go.dev/github.com/antchfx/htmlquery@v1.2.3\">htmlquery</a>, <a href=\"https://pkg.go.dev/github.com/antchfx/htmlquery@v1.2.3\">htmlquery</a> 使用的是<a href=\"https://www.w3school.com.cn/xpath/xpath_syntax.asp\">xpath 选择器</a>。</p>\n<p>github: <a href=\"https://github.com/kaichii/pokemon-clawler\">项目源码</a></p>\n<h2><a href=\"https://pkg.go.dev/github.com/antchfx/htmlquery@v1.2.3\">htmlquery</a> 基本用法</h2>\n<h3>常用方法</h3>\n<h4>LoadURL</h4>\n<pre><code class=\"language-go\">// 根据给定的 url 返回该 url 的 HTML document\nfunc LoadURL(url string) (*html.Node, error)\n</code></pre>\n<h4>Find</h4>\n<pre><code class=\"language-go\">// 返回 top 节点下所有满足 `expr` 的所有节点\nfunc Find(top *html.Node, expr string) []*html.Node\n</code></pre>\n<h4>FindOne</h4>\n<pre><code class=\"language-go\">// 返回 top 节点下满足 `expr` 的第一个节点\nfunc FindOne(top *html.Node, expr string) *html.Node\n</code></pre>\n<h4>InnerText</h4>\n<pre><code class=\"language-go\">// 返回节点 tag 间的文本\nfunc InnerText(n *html.Node) string\n</code></pre>\n<h4>SelectAttr</h4>\n<pre><code class=\"language-go\">// 返回 n 节点上属性名为 name 的属性值\nfunc SelectAttr(n *html.Node, name string) (val string)\n</code></pre>\n<h2>爬取数据</h2>\n<h3>生成要爬取的网页链接</h3>\n<p>根据给定的主页链接，获取需要获取的 pokemon 的主页链接，然后丢到 channel 里，等待后续的处理。</p>\n<pre><code class=\"language-go\">func generateUrls(url string, out chan&#x3C;- string) {\n  doc, err := htmlquery.LoadURL(url)\n\n  utils.CheckError(err, \"[load url]:\")\n\n  nodes, err := htmlquery.QueryAll(doc, \"//table[@class=\\\"a-c roundy eplist bgl-神奇宝贝百科 b-神奇宝贝百科 bw-2\\\"]/tbody/tr/td[last()]/a[@class=\\\"mw-redirect\\\"]\")\n\n  utils.CheckError(err, \"[query //tr/td[last()]/a[@class=\\\"mw-redirect\\\"]]:\")\n\n  for _, a := range nodes {\n    out &#x3C;- fmt.Sprintf(\"%s%s\", baseUrl, htmlquery.SelectAttr(a, \"href\"))  \n  }\n\n  close(out)\n}\n\n</code></pre>\n<h3>提取数据</h3>\n<p>提取链接的 HTML 文本里我们想要获取的数据， 主要就是分析 HTML 文档结构，写出定位到我们需要其数据的文档节点的 xpath 表达式，提取数据就完事了。</p>\n<p>处理 channel in 里链接， 并从中提取数据丢到 channel out 里。</p>\n<pre><code class=\"language-go\">func parse(in &#x3C;-chan string, out chan&#x3C;- []string) {\n  for url := range in {\n\n    log.Println(url)\n\n    name := strings.TrimLeft(url, baseUrl+\"/wiki/\")\n\n    doc, err := htmlquery.LoadURL(url)\n\n    utils.CheckError(err, \"[load url]:\")\n\n    root := htmlquery.FindOne(doc, \"//div[@class=\\\"mw-parser-output\\\"]/table[2]/tbody\")\n\n    result := []string{}\n\n    order := \"\"\n\n    chineseName := \"\"\n\n    imageUri := \"\"\n\n    description := \"\"\n\n    orderNode := htmlquery.FindOne(root, \"//a[@title=\\\"宝可梦列表（按全国图鉴编号）\\\"]\")\n\n    chineseNameNode := htmlquery.FindOne(root, \"//td/span[@style=\\\"font-size:1.5em\\\"]/b\")\n\n    imageNode := htmlquery.FindOne(root, \"/tr[2]//a[@class=\\\"image\\\"]/img\")\n\n    descriptionNode := htmlquery.FindOne(doc, \"//div[@class=\\\"mw-parser-output\\\"]/p[2]\")\n\n    if chineseNameNode != nil {\n      chineseName = htmlquery.InnerText(chineseNameNode)\n    }\n\n    if imageNode != nil {\n      imageUri = \"https:\" + htmlquery.SelectAttr(imageNode, \"data-url\")\n    }\n\n    if descriptionNode != nil {\n      description = strings.Replace(htmlquery.InnerText(descriptionNode), \"\\n\", \"\", -1)\n    }\n\n    if orderNode != nil {\n      order = htmlquery.InnerText(orderNode)\n    }\n\n    result = append(result, order, name, chineseName, imageUri, description)\n\n    out &#x3C;- result\n  }\n\n  close(out)\n}\n</code></pre>\n<h3>导出数据</h3>\n<pre><code class=\"language-go\">func main() {\n\n  result, err := os.Create(\"pokemon.csv\")\n\n  utils.CheckError(err, \"[creat file]:\")\n\n  defer result.Close()\n\n  result.WriteString(\"\\xEF\\xBB\\xBF\")\n\n  writer := csv.NewWriter(result)\n\n  urls := make(chan string)\n  columns := make(chan []string)\n\n  go generateUrls(fmt.Sprintf(\"%s/wiki/%s\", baseUrl, string(\"宝可梦列表（按全国图鉴编号）/简单版\")), urls)\n\n  go parse(urls, columns)\n\n  for c := range columns {\n    err := writer.Write(c)\n\n    utils.CheckError(err, \"[write line]:\")\n  }\n\n  writer.Flush()\n}\n</code></pre>\n"}},"__N_SSG":true}